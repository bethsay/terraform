Terraform allows us to create cloud-agnostic IaC.
All terraform files that we create should have the extention ".tf"
Once IaC is prepared, we get terraform to process all of it with the below command.
    #terraform plan
Once its processed and the output looks good to us, we can use terraform to create that infrastucture with the below command.
    #terraform apply
If you want to delete all the cloud resources created by terraform, then use
    #terraform destroy
Write .tf files -> terraform plan -> terraform apply
terraform Plan will read files and tell us what changes will happen. Once we approve, we should run terraform apply

Lets start with installing terraform on ubuntu
    #wget -O - https://apt.releases.hashicorp.com/gpg | gpg --dearmor -o /etc/apt/keyrings/hashicorp-archive-keyring.gpg
    #echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(grep -oP '(?<=UBUNTU_CODENAME=).*' /etc/os-release || lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/hashicorp.list
    #sudo apt update && sudo apt install terraform
    #terraform -help
To enable autocompletion for terraform commands. This will append a line to ~/.bashrc
    #terraform -install-autocomplete
For other systems, check https://developer.hashicorp.com/terraform/install

Lets understand the core/basic concepts of a terraform project.
    #mkdir 00-basics && cd 00-basics
After we create our IaC, Terraform needs to convert it to the actual apis of that specific cloud vendor. This is done by terraform providers.
Hashicorp and its partners have published these "providers" package at https://registry.terraform.io/browse/providers
Lets start off with using the local provider which has the simple capability of creating files in the local systems.
    #vim providers.tf
Lets paste the code we get when clicking on "Use Provider" at https://registry.terraform.io/providers/hashicorp/local/latest into providers.tf
Now, we need to install this provider package.
    #terraform init
This creates a .terraform folder tree to download the binaries/packages of the required_providers and a .terraform.lock.hcl
If any modification is made to required_providers block, we must re-run terraform init
At the terraform registry page, the Documentation of every provider, will list and describe all the resources that can be managed by the provider.
For local provider, we can create local_file and local_sensitive_file resources. https://registry.terraform.io/providers/hashicorp/local/latest/docs/resources/file
    #vim resources.tf
Lets paste the code of the local_file resource. Lets process our IaC with
    #terraform plan
This command will describe to us all the creations and deletions terraform intends to perform.
If the plan looks good lets implement it with
    #terraform apply
Terraform apply command includes the terraform plan command. Its okay to skip it.
After the first run of terraform apply, it creates a terraform.tfstate file. tfstate file holds the detailed report of resources created by terraform.
Lets make modifications to resource file and see how terraform responds
Keep in mind, the combination or resource_name + resource_type must be unique within a terraform project
    #vim resources.tf
        ->Duplicate the local_file block.
    #terraform apply
        ->Error: Duplicate resource
    #vim resources.tf
        ->Use unique values for resource_name, content and filename.
        ->There wont be error if content and filename are not unique, but results will be problematic
    #terraform apply
From the second run of the terraform apply, terraform.tfstate is renamed to terraform.tfstate.backup and a new terraform.tfstate is created. To see if any resources were destroyed or to do a before-after comparison, this would be useful
    #sdiff -s terraform.tfstate terraform.tfstate.backup
    #vim resources.tf
        ->Add a local_sensitive_file block
    #terraform apply
You will see that the content of the sensitive_resource is masked while the plan was being processed.
This is how keys, passwords and other sensitive variables will be handled by terraform.
Have a look at the tfstate file and the sensitive_resource created by the latest apply.
    #less terraform.tfstate
    #cat training/sensitive_file_by_tf.txt
The sensitive data will be used as is within the tfstate and the resource.
Terraform can format your files and make it easy to read and maintain. This action will not affect the IaC functionalities
To get list of files that would be modified by formatting, use
    #terraform fmt -check
To see the difference before and after running the formatting, use
If -check has an empty response, terraform thinks your files are already formatted properly
To allow terraform to edit all your files with proper spacing, and get the diff response before and after formatting, use
    #terraform fmt -diff
If you trust terraform fmt to make the IaC look nice and dont need any changelog, use
    #terraform fmt
It is good practice to format your IaC before pushing your code to your code repositories.
To delete/destroy all resource tracked by the tfstate (not the IaC) use
    #terraform destroy

When newer versions of local provider is to be used, you will need to edit its version in the required_providers block and run terraform init.
You may prefix the version with an operator. https://developer.hashicorp.com/terraform/language/expressions/version-constraints#operators
Version constraint operators allows terraform to pick the latest from range of provider versions without needing to edit your code each time.
Lets configure the version of local provider to use the latest 2.x.x version.
    #cd 00-basics
    #vim providers.tf
    #head .terraform.lock.hcl
    #terraform init
    #head .terraform.lock.hcl
Although the code is now modified, terraform.lock.hcl has not changed and providers will not automatically update to the latest version
In fact, even if you clone this project to a new machine and perform terraform init,
Terraform will not check if a newer provider exist but will proceed to download and install the current version itself.
When you see a new version of the provider is released, and want to have the upgrade, run
    #head .terraform.lock.hcl
    #terraform init -upgrade
    #ll .terraform/providers/registry.terraform.io/hashicorp/local/
    #head .terraform.lock.hcl
This updates the dependency and installed the new plugin but keeps the old one as well.
Now that an upgrade has been applied. Test the IaC with plan, apply and destroy.
Do not git add, commit or push the Iac to your code repo without full testing.
If the provider upgrade breaks the IaC project and you want to undo the upgrade,
You can edit the version in required_providers with an exact older version that you know was working and re-run upgrade.
    #vim providers.tf
    #terraform init -upgrade
Or if your IaC is tracked by git and you can restore the dependency lock file to before the upgrade and run terraform init.
    #git restore .terraform.lock.hcl
    #terraform init

The download path for the provider plugins is .terraform within the project directory
    #cd 00-basics
    #ll .terraform/providers/registry.terraform.io/hashicorp/<provider>/<version>/<system_arch>/
    #ll -h .terraform/providers/registry.terraform.io/hashicorp/local/2.6.1/linux_amd64/
    #du -csh .terraform/providers
The plugin of local provider and other simple providers are relatively small, about 15MB in size.
But the size of aws, azure and gcp plugins are about 500-700MB each.
When you are running multiple projects on the same system, even if the same providers are used in each project,
You will be wasting space due to duplication of the same plugins in each project.
Also, terraform will be downloading the binary from the internet each time, even though a copy exists in the system.
Also, when you apply provider upgrades, storage utilization gets multiplied.
To relclaim storage after successful upgrade, you will have to cycle through each project and delete the old plugin.
This behaviour can be managed by creating a terraformrc in users home directory
The plugin_cache_dir will be used as the destination for all future plugin downloads that would be performed by terraform init
    #vim terraform.rc
    #cp terraform.rc ~/.terraformrc
Lets test this by deleting our exisiting providers and doing a terraform init re-run
    #du -csh .terraform/providers
    #rm -r .terraform/providers
    #terraform init
    #du -csh .terraform/providers
    #ll -h .terraform/providers/registry.terraform.io/hashicorp/local/2.6.1/
    #ll ~/.terraform.d/plugin-cache/registry.terraform.io/hashicorp/local/2.6.1/linux_amd64/
The plugin that was present under .terraform/providers is now replaced with a symlink to the plugin_cache_dir.
Any new projects with required_providers that exist in plugin_cache_dir will have near instant init times.
An advanced use case of terraformrc is to configure filesystem_mirror as a provider installation source.
Ensure filesystem_mirror path is different from plugin_cache_dir
    #vim terraform.rc
The sample config in terraformrc instructs terraform init to only check the filesystem path if the source of the required_provider is example.com
If the required_providers source is not example.com terraform init should send a download request directly to the URL.
So, if the filesystem_mirror has not been pre-loaded with the providers needed for your project, terraform init will fail.
To pre-load the filesystem_mirror, you can have another machine that has terraform installed and the stubs of all your terraform projects.
Stub of an terraform project is an name for the sections of code that are needed to perform terraform init, ie, providers.tf, ie, terraform blocks.
Navigate to each project stub, and instead of terraform init, run
    #terraform providers mirror /download/path/for/providers
You can choose the download path to be a shared drive between both systems.
Or compress/package the downloads such that directory structure is preserved and transfer to terraform runner machine that need to use filesystem_mirror.
You could aslo temporarily connect your terraform runner machine to an internet gateway and run providers mirror command to populate the filesystem_mirror.

Terraform plan will read our .tf files, parse it with the required_providers installed during init. This can be saved as a plan file.
This is the content that is actually used by terraform. This is then again converted to an output that we can read and understand.
    #cd 00-basics
    #terraform plan -out ./local.tfplan
        ->You can see in stdout the actions that terraform will do if the plan is executed.
        ->This also creates a local.tfplan file. We cant read the file but it can be processed by any terraform client.
    #terraform show ./local.tfplan
        ->This allows us to read a plan before execution
Until now, when terraform apply was run, the plan was shown and we had to approve it for execution.
If we instead try to apply this local.tfplan, we will not see the plan in the stdout and terraform will not wait for an approval before executing it.
    #terraform apply local.tfplan
The plan is bound to the tfstate file during its creation. If the tfstate changes before the plan is applied, it will be considered as stale and cannot be used.
This means the same plan cannot be reused because applying it causes the state to change and the plan to become stale.
Our .tf files can be parsed by terraform plan to create a destroy plan.
    #terraform plan -destroy -out ./local.tfplan
    #terraform show ./local.tfplan
    #terraform apply local.tfplan
Cleaup the stale plan
    #rm local.tfplan
Terraform can execute an apply or destroy without asking for approval when using the flag -auto-approve
    #terraform apply -auto-approve
    #terraform apply -destroy -auto-approve
        ->Same as terraform destroy -auto-approve

Every terraform apply implements the plan and update the terraform.tfstate
    #cd 00-basics
    #less terraform.tfstate
Another way to read the current state is with the terraform state command or the terraform show command
    #terraform state -h
    #terraform state list
        ->Lists all resource.identifier managed in this terraform project.
    #terraform state show local_file.another_resource[1]
        ->Check the details of any of resource.identifier mentioned in the list command.
    #terraform state show local_sensitive_file.sensitive_resource
        ->sensitive data of any resource will be masked just as it was in the stdout of plan and apply
    #terraform show
        ->Shows the state content in the format of terraform blocks of code
    #terraform show -json | jq
        ->Shows the same data as is in terraform.tfstate with minor differences in representation of some keys and values
    #terraform show -json | jq '.values.root_module.resources[].address'
        ->Same as the terraform list command
    #terraform show -json | jq '.values.root_module.resources[] | select(.address=="local_file.another_resource[1]") | .values'
        ->Same as the terraform state show local_file.another_resource[1]
    #terraform show -json | jq '.values.root_module.resources[] | select(.address=="local_file.another_resource[1]") | .values.filename'
        ->Cannot be done with terraform state command, but very useful filters
While the state show command will mask sensitive data, it is stored as plain text in terraform.tfstate
By default, tfstate is stored locally in the project directory, which is unsecure.
You can maintain tfstate at a remote secure location by defining a backend configuration.
In the upcoming 02-aws-iam project of we will have the first look at using s3 bucket as a backend.
Other backends include remote(hcp or enterprise), azurerm blob, googlecs, postgres, k8secret, urls. https://developer.hashicorp.com/terraform/language/backend
Lets revisit to check the subcommands of terraform state.

When plan or apply is being run, the tfstate is pulled into memory. It is compared and updated with the actual infrastucture Configuration.
State Drift is said to have occured if the actual infra is different from the tfstate. This can also be seen as modifications of the in-memory tfstate.
State Drift happens when actual infra is modified without terraform. Here actual state will be different from state file and code.tf
The plan or apply commands then parse tf files of the project with provider and is again compared with the in-memory tfstate and the difference is outputted to us for approval.
Lets cause State Drift in our project.
    #cd 00-basics
    #echo "State Drift is happening" > ./training/file_by_tf.txt
Is this change detected by tf state?
    #less terraform.tfstate
    #terraform state show local_file.resource_name
To see the effect of state drift on tfstate
    #terraform plan -refresh-only
If state drift is unexpected, correct it by applying the IaC and overwrite actual state
    #terraform plan
    #terraform apply
If state drift is intentional and if it must not be corrected by terraform, use the refresh command to update the tfstate reflects the actual state.
    #terraform refresh
Terraform modifications is either a create or destroy. Very rarely change is considered.
So resources that have undergone state drift are often considered as destryed resources according to terraform.
Just as terraform apply includes a plan stage, terraform plan includes a refresh stage.

Every resource_type have their own unique arguments whose values allows us to codeify resource creation.
Terraform has meta-arguments (count, depends_on, for_each) to be used on any resource, and are not restricted by type. https://developer.hashicorp.com/terraform/language/meta-arguments
The count meta-argument can be used to create copies of a resource
    #cd 00-basics
    #vim resources.tf
        ->Add count = 4 into latest local_file blocks
        ->Use the ${count.index} parameter into its filename as well.
    #terraform apply
    #ls -lah training/
    #less terraform.tfstate
Using the -target flag in plan, apply, or destroy command can get terraform to operate on a specific resource.
    #terraform destroy -target=local_file.another_resource[2]
    #terraform apply -target=local_file.another_resource[2]
It is not standard practice to use -target. Its best to edit/comment all the changes in main.tf.
Thats all about the basics. Before we commit and move to advanced terraform use, lets format our code
    #terraform fmt -diff

Variables block in terraform allows us to parameterize the code making it reuseable. https://developer.hashicorp.com/terraform/language/block/variable
Initialize a new project (directory or folder) with a local povider
    #mkdir 00-basics-plus && cd 00-basics-plus
    #vim providers.tf
        ->Use the hashicorp/local as a required_providers.
    #terraform init
Define 2 string variables with a default values.
    #vim variables.tf
Use these variables as filename for local_file resources.
    #vim main.tf
Create the resources
    #terraform plan
    #terraform apply
Add a number variable with a default value
    #vim variables.tf
Use that number as resource multiplier using count meta-arguments in both resources.
While Terraform indexes these resource copies starting from 0 to n-1. We are allowed to use math to number it however we want.
Update filename to have a incremental parent directory of count.index+1
    #vim main.tf
Terraform console allows use to interact with variables and resources even if our IaC has not been applied. This is great for troubleshooting,
    #terraform console
        #var.file1
        #var.replica
        #local_file.file1[0]
        #local_file.file2
It appears that processing of var is done by referencing the code, but the local_file. is processed by referencing the state file
Update the resources
    #terraform apply
    #terraform console
        #local_file.file1
        #local_file.file1[0].content
If default value is not set for a variable, terraform will prompt the value during plan/apply.
    #variables.tf
        ->Comment out default value of replica
    #terraform console
        #var.replica
    #terraform apply
    #variables.tf
        ->Uncomment default value of replica
    #terraform console
        #var.replica
Updating the value of an input variable can by done during plan or apply using "-var"
    #terraform apply -var replica=5
But most often you would maintain all your variables in a file.
Create a file with key=value pairs. Ensure key is same as the variables used.
    #vim values.txt
Pass this file name with the -var-file flag in plan, apply or console command.
    #terraform plan -var-file values.txt
For the values file to be picked up by terraform without -var-file, it must be named terraform.tfvars or have the extention *.auto.tfvars
    #mv values.txt terraform.tfvars
    #terraform plan
    #mv terraform.tfvars my_values.auto.tfvars
    #terraform console
        #var.replica
        #local_file.file1[0].content
    #terraform apply
    #mv my_values.auto.tfvars values.txt
The types primitive variables available are string, number, bool. https://developer.hashicorp.com/terraform/language/expressions/types

Locals block in terraform allows for the substitution of repeating values within a project with a key. https://developer.hashicorp.com/terraform/language/block/locals
locals block is also used to maintain the value of a function/expression in a key that can be used repeatedly.
This is better than processing the function repeatedly. https://developer.hashicorp.com/terraform/language/functions
    #cd 00-basics-plus
Create a local block to uppercase a string and use it as the new parent directory of all resources
    #vim main.tf
See if terraform can use the modification
    #terraform console
        #local.app
        #upper(local.app)
        #local.path
    #terraform apply -var-file values.txt

Lets try out some complex types in variables like list, set and map. https://developer.hashicorp.com/terraform/language/expressions/types
    #cd 00-basics-plus
Create 2 variables. One must accept a set of strings with at least 2 default values
And the other variable must accept a map of objects with at least 2 objects. Each object is a key value pair.
    #vim variables.tf
    #terraform console
        #var.env
        #var.component
Lets use these variables as the content and filename for new resources.
for_each is the meta-argument can cycle through the variables within often the sets and maps. for_each can only work with sets and maps
    #vim main.tf
Can terraform make a plan with these variables?
    #terraform plan
If the default values picked up successfully, lets apply it with custom values that we will define in values file.
    #vim values.txt
    #terraform apply -var-file values.txt
    #terraform console -var-file values.txt
        #var.env
        #local_file.env_files_set["dev"]
        #var.component
        #local_file.component_files["backend"]
Lets try the formatlist function to add file extention to var.env
    #terraform console -var-file values.txt
        #formatlist("%s.%s",var.env,"md")
Lets add this formatlist expression as env_ext into the locals block
    #vim main.tf
The variable types list and set very similar. They have the same data constraints but differ in how they are referenced
Update the type of var.env to list type.
    #vim variables.txt
Create a new resource whose count is size of list, filename is made up by env_ext, and content and filename cycle through count.index
    #vim main.tf
    #terraform apply -var-file values.txt
The elements of a set  are refered by their key name.
The elements of a list are refered by their index.
    #terraform console -var-file values.txt
        #local_file.env_files_list[0].filename
        #local_file.env_files_set["dev"].filename
        #local_file.env_files_list[*].filename
        #keys(local_file.env_files_set)[*]
        #values(local_file.env_files_set)[*].filename
        #[for key in local_file.env_files_list : key.filename]
        #[for key in local_file.env_files_set : key.filename]
Complex type variables can nest/contain other complex data. Create a variable that accepts a nested map.
    #vim variables.tf
Type specification is optional for variables. You may set variable type as 'any' when you are not trying to be restrictive.
Cycling through the nested map can be done with for_each. Where we had used each.key and each.values, we will need to use each.key and each.value.subkey
    #vim main.tf
Can terraform make a plan with these variables?
    #terraform plan
If the default values picked up successfully, lets apply it with custom values that we will define in values file.
    #vim values.txt
    #terraform apply -var-file values.txt
    #terraform console -var-file values.txt
        #var.content
        #local_file.content_files["index"]
        #values(local_file.content_files)[*].content
        #[for key in local_file.content_files : key.content]

Output blocks in terraform are used to share relevant information after deploying a project.
This is often used to create a summary on stdout or to send data to another tool for further processing.
    #cd 00-basics-plus
We can tally the number of resources created by using the length function on each local_file resource and adding them up
    #terraform console -var-file values.txt
        #length(local_file.file1) + length(local_file.file2) + .. + ..
We can fetch the parent directory where all files have been created into.
    #terraform console -var-file values.txt
        #local.path
We can pull some of the filenames that our IaC has created.
    #terraform console -var-file values.txt
        #local_file.file1[*].filename
Create output blocks to display these three properties of our project.
    #vim outputs.tf
    #terraform plan
The output.path is relative. You can make it absolute path with functions like abspath or path.cwd+trimprefix
    #terraform console -var-file values.txt
        #abspath(local.path)
        #"${path.cwd}${trimprefix(local.path, ".")}"
The output.items repeats the parent path for each file. You can filter it out using functions like basename, trimprefix, regex, element+split within a for loop.
    #terraform console -var-file values.txt
        #[for attr in local_file.content_files : basename(attr.filename)]
        #[for attr in local_file.content_files : trimprefix(attr.filename,"${local.path}/")]
        #[for attr in local_file.content_files : regex("([^/]+)$",attr.filename)[0]]
        #[for attr in local_file.content_files : element(split("/",attr.filename),-1)]
Update the output block with this change
    #vim outputs.tf
    #terraform apply -var-file values.txt
As all the resources in this project are managing files locally, we could use fileset function.
The output.count can be length of fileset function.
    #terraform console -var-file values.txt
        #length(fileset(local.path,"*"))
The output.items can be All files in local.path or some files files of fileset filtered using the slice or element+chunklist functions
    #terraform console -var-file values.txt
        #fileset(local.path,"*")
        #slice(tolist(fileset(local.path,"*")),0,5)
        #element(chunklist(tolist(fileset(local.path,"*")),5),0)))
Update the output block with this change
    #vim outputs.tf
    #terraform apply -var-file values.txt
After an apply, the output is also recorded as part of the state. To view them, you can
    #terraform output
    #terraform output items
Any of the output can be made sensitive. Set output.path as sensitive
    #vim outputs.tf
    #terraform apply -var-file values.txt
    #terraform output
Sensitive output would be masked during plan, apply and output. But it will be visible when specifically querrying it.
    #terraform output path
Lets set sensitive as false for output.path
    #vim outputs.tf
    #terraform apply -var-file values.txt

The problem with using fileset function is that it operates only exisiting files and cannot reflect to changes made by the running terraform plan/apply
Use the default values of all out variables with a terraform apply
    #terraform apply
    #terraform output
Even though all the files have changed, output.count and output.items are reflecting the old state.
    #terraform apply
    #terraform output
Now the output matches the actual files.
This is because every functions and expressions get evaluated/processed before any of the blocks are processed, unless there is an implicit dependency.
If an parameter/argument of any function/expression is a terraform resource, its evaluation is delayed until the resource has been processed by terraform plan.
If output.items is using the slice or element+chunklist operation, terraform plan/apply will fail with an error if it is followed by a destroy.
    #terraform destroy
    #terraform apply -var-file values.txt
The fileset function can be used as is in output.items and be used with length function in output.count.
But to get an accurate value when working with dynamic files in terraform, perform operations/functions on the local_file resource instead of fileset.
Change the values of output.count and output.items back to sum of lengths of local_files and basename of local_file
    #vim outputs.tf
    #terraform apply -var-file values.txt

Data blocks in terraform are used to extract properties of any resource supported by a provider.
The local provider, supports data sources of type local_file and local_sensitive_file. https://registry.terraform.io/providers/hashicorp/local/latest/docs/data-sources/file
Create a set of the files that you would want to read
    #terraform console -var-file values.txt
        #toset(values(local_file.content_files)[*].filename)
        #toset([for attr in local_file.content_files : basename(attr.filename)])
Create a data block whose filename would cycle through each of elements of either set.
    #vim outputs.tf
Create an output block that will loop through each filename and fetch its content. You could use trimspace function with it.
    #vim outputs.tf
Here, we had used data block to read properties of resources created by our IaC. If this looks like its unnecessary, thats because it is.
In real seanrios, it is used to read properties of resources that were not created by the project.

depends_on is a meta-argument used to define dependencies for a block. It can be used in any blocks except locals and variables.

lifecycle is a meta-argument that can manage the creation and deletions of resources.
    ->create_before_destroy = false
        ->This is the default setting. When IaC has to implement a change but the resource does not support live modification, terraform will destroy then recreate the resource
        ->Setting this to true could mitigate downtime but can fail if there is a unique name constraint.
        ->This config is propagates to all upstream dependencies. terraform plan/apply would fail if you try to overwrite this implied lifecycle om any upstram resource. 
    ->prevent_destroy = true
        ->This setting will cause the plan/apply to fail with error if terraform needs to destroy the resource to implement a change.
    ->ignore_changes = [ resource_type.resource_name.attribute ]
        ->Use this if any attributes of a real infra could change, and be detected by terraform as drift, but is not required by IaC to correct.
        ->If the list of attributes is replaced will 'all', then the IaC will be responsible for create and destroy, but will not apply updates.
    ->replace_triggered_by = [ resource_type.resource_name, resource_type.resource_name["key"], resource_type.resource_name.attribute ]
        ->Use this to recreate the resource if the same plan/apply will modify another resource, element(resource) or attribute(element(resource)) of the same project.
    ->precondition = { condition = expression(), error_message = "String"}
        ->Use this if you want your resource creation/modification to occur only if condition is true.
        ->When condition is false, resource is skipped and error_message is returned as warning to stdout/console
    ->postcondition = { condition = expression(), error_message = "String"}
        ->Use this if you want downstream dependencies to be evaluated only if condition is true
        ->When condition is false, resource is created/modified and error_message is returned as warning to stdout/console

Thats all about the advanced topics. Before we commit and move to basics of terraform modules use, lets format our code
    #terraform fmt -diff

-------------------------PENDING: Try the provisioner blocks within resources-------------------------
Modules are a fully working terraform project that can be reused in other project like an add-on package.
Any project that we create is called the root module. Lets create one
    #mkdir 00-basics-modules
This root module can contain other projects like a package. These are called child modules. Lets create one.
    #mkdir 00-basics-modules/child_module
Hashicorp maintains a registry of modules we can use in our root module. https://registry.terraform.io/browse/modules
Let use code from 00-basics-plus to create a child module.
    #vim ./00-basics-modules/child_module/providers.tf
        ->Use hashicorp/local as a required_providers
    #vim ./00-basics-modules/child_module/main.tf
        ->Use the locals block along with the env_files_set and component_files resource blocks from ./00-basics-plus/main.tf
    #vim ./00-basics-modules/child_module/variables.tf
        ->Use the env and component variables from ./00-basics-plus/variables.tf
    #vim ./00-basics-modules/child_module/outputs.tf
        ->Use path, items and count output from ./00-basics-plus/outputs.tf
        ->No need to make it human-readable, so skip the format function
        ->Update the output values so that it reflects the data available in ./modules/child_module/main.tf
Now lets create our root module. Usually you would include required_providers block.
Since the only resources that will be created are using the child_module, we can skip it.
    #vim 00-basics-modules/main.tf
        ->Create module block with the source as ./child_module
        ->Copy the values for env and component from ./00-basics-plus/values.txt into the module block
        ->Create a output block whose value would be a set of count, path and items output of the module
Lets Initialize and apply our root module
    #terraform init
    #terraform apply
    #terraform output
Thats all about modules topic. Before we commit, lets format our code
    #terraform fmt -check
    #terraform fmt -check -recursive
    #terraform fmt -diff -recursive
